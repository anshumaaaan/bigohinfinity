{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4N0O8UGVHyf"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "IMG_SIZE = 100\n",
        "\n",
        "class Model(tf.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        # Load the base model with the correct input shape and remove the top layer\n",
        "        base_model = keras.applications.DenseNet201(\n",
        "            include_top=False,  # Remove the fully connected layers on top\n",
        "            weights=\"imagenet\",\n",
        "            input_tensor=None,\n",
        "            input_shape=(224, 224, 3),\n",
        "            pooling=None,\n",
        "        )\n",
        "        base_model.trainable = False  # Freeze the base model\n",
        "\n",
        "        # Build the custom model\n",
        "        self.model = tf.keras.Sequential([\n",
        "            # Input layer\n",
        "            tf.keras.Input(shape=(100, 100, 3)),\n",
        "\n",
        "            # Augmentation layers\n",
        "            RandomCrop(height=100, width=100),  # RandomCrop to the input size (optional, can be adjusted)\n",
        "            tf.keras.layers.Resizing(224, 224),  # Resize images to match ResNet101V2 input size\n",
        "            RandomFlip(mode='horizontal'),\n",
        "            RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
        "            RandomRotation(factor=0.2),\n",
        "            RandomZoom(height_factor=0.1, width_factor=0.1),\n",
        "            RandomContrast(factor=0.2),\n",
        "            RandomBrightness(factor=0.2),\n",
        "\n",
        "            # Base model\n",
        "            base_model,\n",
        "\n",
        "            # Global average pooling to reduce dimensions\n",
        "            tf.keras.layers.GlobalAveragePooling2D(),\n",
        "\n",
        "            # Fully connected layers\n",
        "            tf.keras.layers.Dense(256, activation='relu'),\n",
        "            tf.keras.layers.Dense(128, activation='relu'),\n",
        "            tf.keras.layers.Dense(64, activation='relu'),\n",
        "\n",
        "            # Output layer for 3 classes\n",
        "            tf.keras.layers.Dense(3, activation='softmax')\n",
        "        ])\n",
        "\n",
        "        self.model.compile(\n",
        "            optimizer=tf.keras.optimizers.SGD(learning_rate=0.1),\n",
        "            loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "            metrics=[tf.keras.metrics.CategoricalAccuracy()]\n",
        "        )\n",
        "\n",
        "    # The `train` function takes a batch of input images and labels.\n",
        "    @tf.function(input_signature=[\n",
        "        tf.TensorSpec([None, IMG_SIZE, IMG_SIZE, 3], tf.float32),\n",
        "        tf.TensorSpec([None, 3], tf.float32)\n",
        "    ])\n",
        "    def train(self, x, y):\n",
        "        with tf.GradientTape() as tape:\n",
        "            prediction = self.model(x)\n",
        "            loss = self.model.loss(y, prediction)\n",
        "        gradients = tape.gradient(loss, self.model.trainable_variables)\n",
        "        self.model.optimizer.apply_gradients(\n",
        "            zip(gradients, self.model.trainable_variables))\n",
        "        result = {\"loss\": loss}\n",
        "        return result\n",
        "\n",
        "    @tf.function(input_signature=[\n",
        "        tf.TensorSpec([None, IMG_SIZE, IMG_SIZE, 3], tf.float32),\n",
        "    ])\n",
        "    def infer(self, x):\n",
        "        logits = self.model(x)\n",
        "        probabilities = tf.nn.softmax(logits, axis=-1)\n",
        "        return {\n",
        "            \"output\": probabilities,\n",
        "            \"logits\": logits\n",
        "        }\n",
        "\n",
        "    @tf.function(input_signature=[tf.TensorSpec(shape=[], dtype=tf.string)])\n",
        "    def save(self, checkpoint_path):\n",
        "        tensor_names = [weight.name for weight in self.model.weights]\n",
        "        tensors_to_save = [weight.read_value() for weight in self.model.weights]\n",
        "        tf.raw_ops.Save(\n",
        "            filename=checkpoint_path, tensor_names=tensor_names,\n",
        "            data=tensors_to_save, name='save')\n",
        "        return {\n",
        "            \"checkpoint_path\": checkpoint_path\n",
        "        }\n",
        "\n",
        "    @tf.function(input_signature=[tf.TensorSpec(shape=[], dtype=tf.string)])\n",
        "    def restore(self, checkpoint_path):\n",
        "        restored_tensors = {}\n",
        "        for var in self.model.weights:\n",
        "            restored = tf.raw_ops.Restore(\n",
        "                file_pattern=checkpoint_path, tensor_name=var.name, dt=var.dtype,\n",
        "                name='restore')\n",
        "            var.assign(restored)\n",
        "            restored_tensors[var.name] = restored\n",
        "        return restored_tensors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqc4TbbOVtbC",
        "outputId": "6c004479-a345-43c1-bb95-a59cf250b8ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1313 images belonging to 3 classes.\n",
            "Found 110 images belonging to 3 classes.\n",
            "Found 64 images belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "test2_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "train_dataset = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/ chess/ dataset/train',  # Replace with the path to your training dataset\n",
        "    target_size=(100, 100),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'  # Ensure labels are one-hot encoded\n",
        ")\n",
        "\n",
        "test_dataset = test_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/ chess/ dataset/test',  # Replace with the path to your validation dataset\n",
        "    target_size=(100, 100),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'  # Ensure labels are one-hot encoded\n",
        ")\n",
        "\n",
        "test2_dataset = test2_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/ chess/ dataset/test2',  # Replace with the path to your training dataset\n",
        "    target_size=(100, 100),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'  # Ensure labels are one-hot encoded\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "349z3ukYWoh_"
      },
      "outputs": [],
      "source": [
        "# Extract a batch of data for tuning\n",
        "train_img, train_labels = next(train_dataset)\n",
        "test_img, test_labels = next(test_dataset)\n",
        "test2_img, test2_labels = next(test2_dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "I7O_SJeqWsly",
        "outputId": "ec5f3215-767d-45af-a348-7378f1748948"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - categorical_accuracy: 0.3200 - loss: 1.1092 - val_categorical_accuracy: 0.7143 - val_loss: 0.8359\n",
            "Epoch 2/1000\n",
           "Epoch 1000/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - categorical_accuracy: 0.6800 - loss: 0.7626 - val_categorical_accuracy: 1.0000 - val_loss: 0.0160\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7864fbf2fa00>"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_instance = Model()\n",
        "\n",
        "# Train the model\n",
        "model_instance.model.fit(train_img,train_labels, epochs=1000, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8-AWSQnGcPrp",
        "outputId": "6615d4a3-74a3-4155-cc08-b5744493cabf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 501/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - categorical_accuracy: 0.6000 - loss: 0.8145 - val_categorical_accuracy: 1.0000 - val_loss: 0.0035\n",
            "Epoch 502/3000\n",
             "Epoch 3000/3000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - categorical_accuracy: 0.6000 - loss: 0.8011 - val_categorical_accuracy: 1.0000 - val_loss: 1.8739e-04\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78642c433040>"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_instance.model.fit(train_img,train_labels, epochs=1000, validation_split=0.2)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
